{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove란?\n",
    "- Glove는 (Global Vectors for Word Representatin)의 약자이다\n",
    "- 카운트 기반의 LSA , 예측기반의 Word2Vec 의 단점을 지적하며 보완하기 위해 나온 단어임베딩 방법론이다 .\n",
    "- 실제로도 Word2Vec만큼 뛰어난 성능을 보여주고 , 현재 단정적으로 Word2Vec와 Glove중 어떤것이 뛰어나다고 말하기는 힘듦. 보통 둘다 사용하고 성능이 더 좋은것 사용한다고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 방법론에 대한 비판\n",
    "- LSA는 카운트 기반으로 통계정보를 고려하긴 하지만 , 왕 : 남자 = 여왕?(정답은 여자) 와 같은 단어 의미의 유추작업에서는 성능이 상당히 떨어짐.\n",
    "- Word2vec은 유추작업에서는 LSA보다 뛰어나지만 사용자가 정해놓는 window 크기 내에서만 주변단어를 고려해서 전체적인 통계정보를 반영하지 못한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이론적인 내용은 동시등장확률 , 동시등장행렬을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) 윈도우 기반 동시 등장 행렬(Window based Co-occurrence Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Word2Vec과 마찬가지로 , 윈도우의 크기가 N일때 , 좌, 우에 존재하는 N개의 단어만 참고\n",
    "- Ex)\n",
    "    - I like deep learning\n",
    "    - I like NLP\n",
    "    - I enjoy flying\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "카운트|I   like|enjoy|deep|learning|NLP|flying\n",
    "---|---|---|---|---|---|---\n",
    "I|0|2|1|0|0|0|0\n",
    "like|2|0|0|1|0|1|0\n",
    "enjoy|1|0|0|0|0|0|1\n",
    "deep|0|1|0|0|1|0|0\n",
    "learning|0|0|0|1|0|0|0\n",
    "NLP|0|1|0|0|0|0|0\n",
    "flying|0|0|1|0|0|0|0\n",
    "\n",
    "__<center>윈도우가 1일때 , 위 텍스트를 가지고 구성한 동시등장행렬</center>__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) 동시 등장 확률(Co-occurrence Probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 동시 등장 확률 __P(k | i)__는 동시 등장 행렬로부터 특정 단어 ___i___의 전체 등장 횟수를 카운트하고, 특정 단어 ___i___가 등장했을 때 어떤 단어 ___k___가 등장한 횟수를 카운트하여 계산한 __조건부 확률__\n",
    "\n",
    "- __P(k | i)__ 에서 i를 __중심 단어__(Center Word), k를 __주변 단어__(Context Word)라고 하자.\n",
    "- __동시등장행렬__에서 __중심단어__ i의 행의 모든 값을 더한 값을 분모로 하고 i행 k열의 값을 분자로 한 값이라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동시등장확률 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동시 등장 확률과 크기 관계 비(ratio)|k=solid|k=gas|k=water|k=fasion\n",
    "---|---|---|---|---\n",
    "P(k l ice)|0.00019|0.000066|0.003|0.000017\n",
    "P(k l steam)|0.000022|0.00078|0.0022|0.000018\n",
    "P(k l ice) / P(k l steam)|8.9|0.085|1.36|0.96\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 표를 통해 알 수 있는 사실은 solid가 등장했을 때 ice가 등장할 확률 0.00019은 solid가 등장했을 때 steam이 등장할 확률인 0.000022보다 약 8.9배 크다. \n",
    "- 그도 그럴 것이 solid는 '단단한'이라는 의미를 가졌으니까 '증기'라는 의미를 가지는 steam보다는 당연히 '얼음'이라는 의미를 가지는 ice라는 단어와 더 자주 등장할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체적인 이론 내용은 생략..\n",
    "너무 깊게 공부할 필요성은 없어보임.. 행렬과 확률기반의 Word2Vec<br>\n",
    "참고 링크 : https://wikidocs.net/22885"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove 훈련시키기 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install glove\n",
    "#pip install glove_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'glove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ac81df12682c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mglove\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCorpus\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mGlove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'glove'"
     ]
    }
   ],
   "source": [
    "from glove import Corpus , Glove\n",
    "\n",
    "corpus = Corpus()\n",
    "corpus.fit(result, window = 5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
