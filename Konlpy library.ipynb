{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://konlpy.org/_/downloads/en/latest/pdf/ 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- morphs : 형태소 추출\n",
    ">- pos : 품사 태깅(Part-of-speech tagging)\n",
    ">- nouns : 명사 추출\n",
    ">- sentences : 문장 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time analysis\n",
    "1. Loading Time : class loading time , including dictionary loads\n",
    "    - Kkma : 5.6988초\n",
    "    - Komoran : 5.4866초\n",
    "    - Hannanum : 0.6591초\n",
    "    - Okt : 1.4870초\n",
    "    - Mecab : 0.0007초\n",
    "        - 확연하게 라이브러리 별로 로딩시간이 존재하는것을 볼 수 있다.\n",
    "2. Execution Time : Time for executing the pos method for each class , with 100K characters\n",
    "    - Kkma : 35.6초\n",
    "    - Komoran : 25.6초\n",
    "    - Hannanum : 8.8초\n",
    "    - Okt : 2.47초\n",
    "    - Mecab : 0.283초\n",
    "        - 실행 시간또한 라이브러리에 따라 달라진다 . 비교적 Mecab이 빠른 편이다\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding collocations \n",
    "\n",
    ">- collocation : 연어(어떤 언어 내에서 특정한 뜻을 나타낼 때 흔히 함께 쓰이는 단어들의 결합)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collocations among tagged words:\n",
      "[(('가부', 'NNG'), ('동수', 'NNG')),\n",
      " (('강제', 'NNG'), ('노역', 'NNG')),\n",
      " (('경자', 'NNG'), ('유전', 'NNG')),\n",
      " (('고', 'ECS'), ('채취', 'NNG')),\n",
      " (('공무', 'NNG'), ('담임', 'NNG')),\n",
      " (('공중', 'NNG'), ('도덕', 'NNG')),\n",
      " (('과반', 'NNG'), ('수가', 'NNG')),\n",
      " (('교전', 'NNG'), ('상태', 'NNG')),\n",
      " (('그러', 'VV'), ('나', 'ECE')),\n",
      " (('기본적', 'NNG'), ('인권', 'NNG'))]\n",
      "\n",
      "Collocations among words:\n",
      "[('현행', '범인'),\n",
      " ('형의', '선고'),\n",
      " ('내부', '규율'),\n",
      " ('정치적', '중립성'),\n",
      " ('누구', '든지'),\n",
      " ('회계', '연도'),\n",
      " ('지체', '없이'),\n",
      " ('평화적', '통일'),\n",
      " ('형사', '피고인'),\n",
      " ('지방', '자치')]\n",
      "\n",
      "Collocations among tags:\n",
      "[('XR', 'XSA'), ('JKC', 'VCN'), ('EPT', 'EPT'), ('VCN', 'ECD'), ('ECD', 'VX')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from konlpy.corpus import kolaw\n",
    "from konlpy.utils import pprint\n",
    "from nltk import collocations\n",
    "\n",
    "measures = collocations.BigramAssocMeasures()\n",
    "\n",
    "\n",
    "#koloaw 라는 대한민국 헌법 관련 텍스트를 불러오는 과정\n",
    "doc = kolaw.open('constitution.txt').read()\n",
    "\n",
    "print('\\nCollocations among tagged words:')\n",
    "tagged_words = Kkma().pos(doc)\n",
    "finder = collocations.BigramCollocationFinder.from_words(tagged_words)\n",
    "pprint(finder.nbest(measures.pmi, 10)) # top 5 n-grams with highest PMI\n",
    "\n",
    "print('\\nCollocations among words:')\n",
    "words = [w for w, t in tagged_words]\n",
    "ignored_words = [u'안녕']\n",
    "finder = collocations.BigramCollocationFinder.from_words(words)\n",
    "finder.apply_word_filter(lambda w: len(w) < 2 or w in ignored_words)\n",
    "finder.apply_freq_filter(3) # only bigrams that appear 3+ times\n",
    "pprint(finder.nbest(measures.pmi, 10))\n",
    "\n",
    "print('\\nCollocations among tags:')\n",
    "tags = [t for w, t in tagged_words]\n",
    "finder = collocations.BigramCollocationFinder.from_words(tags)\n",
    "pprint(finder.nbest(measures.pmi, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collocation(연어) 활용 예제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collocations among tagged words:\n",
      "[(('가슴', 'NNG'), ('일편단심', 'NNG')),\n",
      " (('가을', 'NNG'), ('하늘', 'NNG')),\n",
      " (('공', 'NNG'), ('활', 'NNG')),\n",
      " (('과', 'JC'), ('백두산', 'NNP')),\n",
      " (('구름', 'NNG'), ('없이', 'MAG')),\n",
      " (('기상', 'NNG'), ('과', 'JKM')),\n",
      " (('기상일', 'NNG'), ('세', 'MDN')),\n",
      " (('나라', 'NNG'), ('사랑', 'NNG')),\n",
      " (('남산', 'NNP'), ('위', 'NNG')),\n",
      " (('다하', 'VV'), ('여', 'ECS'))]\n",
      "\n",
      "Collocations among words:\n",
      "[('가슴', '일편단심'),\n",
      " ('가을', '하늘'),\n",
      " ('구름', '없이'),\n",
      " ('나라', '사랑'),\n",
      " ('도록', '하느님'),\n",
      " ('만세', '남산'),\n",
      " ('바람', '서리'),\n",
      " ('보우', '하사'),\n",
      " ('사랑', '하세'),\n",
      " ('서리', '불변')]\n",
      "\n",
      "Collocations among tags:\n",
      "[('VCP', 'EFN'), ('EFN', 'MDT'), ('ETN', 'JX'), ('JC', 'NNP'), ('JX', 'NP')]\n"
     ]
    }
   ],
   "source": [
    "text = '동해 물과 백두산이 마르고 닳도록\\\n",
    "    하느님이 보우하사 우리나라 만세\\\n",
    "    남산 위에 저 소나무 철갑을 두른 듯\\\n",
    "    바람서리 불변함은 우리 기상일세\\\n",
    "    가을 하늘 공활한데 높고 구름 없이\\\n",
    "    밝은 달은 우리 가슴 일편단심일세\\\n",
    "    이 기상과 이 맘으로 충성을 다하여\\\n",
    "    괴로우나 즐거우나 나라 사랑하세'\n",
    "\n",
    "print('\\nCollocations among tagged words:')\n",
    "tagged_words = Kkma().pos(text)\n",
    "finder = collocations.BigramCollocationFinder.from_words(tagged_words)\n",
    "pprint(finder.nbest(measures.pmi, 10)) # top 5 n-grams with highest PMI\n",
    "\n",
    "print('\\nCollocations among words:')\n",
    "words = [w for w, t in tagged_words]\n",
    "finder = collocations.BigramCollocationFinder.from_words(words)\n",
    "finder.apply_word_filter(lambda w: len(w) < 2)\n",
    "finder.apply_freq_filter(1) # 한번이라도 나온 것들로?\n",
    "pprint(finder.nbest(measures.pmi, 10))\n",
    "\n",
    "print('\\nCollocations among tags:')\n",
    "tags = [t for w, t in tagged_words]\n",
    "finder = collocations.BigramCollocationFinder.from_words(tags)\n",
    "pprint(finder.nbest(measures.pmi, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking \n",
    ">- 단기기억의 제한된 용량을 극복하는 방법의 하나로 정보의 개별적 단위를 보다 큰 의미 있는 단위로 묶는 것이다.\n",
    ">- 정보는 크기가 아닌 단위 수가 작업기억의 한계와 관련되므로 각각의 정보를 큰 단위로 묶으면 더 많은 정보를 보유할 수 있게 된다.\n",
    ">- 전화번호를 국번과 번호로 나누는 것도 기억을 돕는 청킹의 전략이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "import nltk\n",
    "# POS tag a sentence\n",
    "sentence = u'만 6세 이하의 초등학교 취학 전 자녀를 양육하기 위해서는'\n",
    "words = konlpy.tag.Okt().pos(sentence)\n",
    "\n",
    "# Define a chunk grammar, or chunking rules, then chunk\n",
    "grammar = \"\"\"\n",
    "NP: {<N.*>*<Suffix>?} # Noun phrase\n",
    "VP: {<V.*>*}          # Verb phrase\n",
    "AP: {<A.*>*}          # Adjective phrase\n",
    "\"\"\"\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "chunks = parser.parse(words)\n",
    "        \n",
    "# Display the chunk tree\n",
    "chunks.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KONLPY 대표 라이브러리\n",
    "- 1.Hannanum\n",
    "- 2.Kkma\n",
    "- 3.Komoran\n",
    "- 4.Mecab\n",
    "- 5.Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hannanum Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[('롯데마트', 'ncn'), ('의', 'jcm')], [('롯데마트의', 'ncn')], [('롯데마트', 'nqq'), ('의', 'jcm')], [('롯데마트의', 'nqq')]], [[('흑마늘', 'ncn')], [('흑마늘', 'nqq')]], [[('양념', 'ncn')]], [[('치킨', 'ncn'), ('이', 'jcc')], [('치킨', 'ncn'), ('이', 'jcs')], [('치킨', 'ncn'), ('이', 'ncn')]], [[('논란', 'ncpa'), ('이', 'jcc')], [('논란', 'ncpa'), ('이', 'jcs')], [('논란', 'ncpa'), ('이', 'ncn')]], [[('되', 'nbu'), ('고', 'jcj')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecc')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecs')], [('되', 'nbu'), ('이', 'jp'), ('고', 'ecx')], [('되', 'paa'), ('고', 'ecc')], [('되', 'paa'), ('고', 'ecs')], [('되', 'paa'), ('고', 'ecx')], [('되', 'pvg'), ('고', 'ecc')], [('되', 'pvg'), ('고', 'ecs')], [('되', 'pvg'), ('고', 'ecx')], [('되', 'px'), ('고', 'ecc')], [('되', 'px'), ('고', 'ecs')], [('되', 'px'), ('고', 'ecx')]], [[('있', 'paa'), ('다', 'ef')], [('있', 'px'), ('다', 'ef')]], [[('.', 'sf')], [('.', 'sy')]]] \n",
      "\n",
      "\n",
      "['롯데마트', '흑마늘', '양념', '치킨', '논란'] \n",
      "\n",
      "\n",
      "['다람쥐', '쳇바퀴', '타고파'] \n",
      "\n",
      "\n",
      "[('웃', 'P'), ('으면', 'E'), ('더', 'M'), ('행복', 'N'), ('하', 'X'), ('ㅂ니다', 'E'), ('!', 'S')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "print(hannanum.analyze('롯데마트의 흑마늘 양념 치킨이 논란이 되고 있다.'),'\\n\\n')\n",
    "print(hannanum.nouns('롯데마트의 흑마늘 양념 치킨이 논란이 되고 있다.'),'\\n\\n')\n",
    "print(hannanum.nouns('다람쥐 헌 쳇바퀴에 타고파'),'\\n\\n')\n",
    "print(hannanum.pos('웃으면 더 행복합니다!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Kkma Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['공부', '를', '하', '면', '하', 'ㄹ수록', '모르', '는', '것', '이', '많', '다는', '것', '을', '알', '게', '되', 'ㅂ니다', '.'] \n",
      "\n",
      "\n",
      "['물', '백두산'] \n",
      "\n",
      "\n",
      "[('하느님', 'NNG'), ('이', 'JKS'), ('보우', 'NNG'), ('하사', 'NNG'), ('우리', 'NP'), ('나라', 'NNG'), ('만세', 'NNG')] \n",
      "\n",
      "\n",
      "['무궁화 삼천리 화려 강산이다 .', '대한 사람 대한으로 길이 보전하자!']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "print(kkma.morphs('공부를 하면 할수록 모르는게 많다는 것을 알게 됩니다.'),'\\n\\n')\n",
    "print(kkma.nouns('동해물과 백두산이 마르고 닳도록 ...'),'\\n\\n')\n",
    "print(kkma.pos('하느님이 보우하사 우리 나라 만세'),'\\n\\n')\n",
    "print(kkma.sentences('무궁화 삼천리 화려강산이다 . 대한사람 대한으로 길이 보전하자!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Komoran "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['우왕', '코', '모란', '도', '오픈', '소스', '가', '되', '었', '어요'] \n",
      "\n",
      "\n",
      "['오픈', '소스', '관심', '개발자'] \n",
      "\n",
      "\n",
      "[('혹시', 'MAG'), ('바람과 함께 사라지다', 'NNP'), ('봄', 'NNG'), ('?', 'SF')] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran(userdic='/tmp/dic.txt')\n",
    "print(komoran.morphs('우왕 코모란도 오픈소스가 되었어요'),'\\n\\n')\n",
    "print(komoran.nouns('오픈소스에 관심 많은 멋진 개발자님들!'),'\\n\\n')\n",
    "print(komoran.pos('혹시 바람과 함께 사라지다 봄?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mecab\n",
    "\n",
    "- Mecab은 윈도우에서는 사용이 안된다고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Okt\n",
    "- 과거에는 Twitter라는 모듈로 사용되었다고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['단독', '입찰', '보다', '복수', '입찰', '의', '경우']\n",
      "['항공기', '체계', '종합', '개발', '경험']\n",
      "['날카로운 분석', '날카로운 분석과 신뢰감', '날카로운 분석과 신뢰감 있는 진행', '분석', '신뢰', '진행']\n",
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나욬', 'Noun'), ('ㅋㅋ', 'KoreanParticle')]\n",
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나요', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n",
      "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되다', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "print(okt.morphs(u'단독입찰보다 복수입찰의 경우'))\n",
    "print(okt.nouns(u'유일하게 항공기 체계 종합개발 경험을 갖고 있는 KAI는'))\n",
    "print(okt.phrases(u'날카로운 분석과 신뢰감 있는 진행으로'))\n",
    "print(okt.pos(u'이것도 되나욬ㅋㅋ'))\n",
    "print(okt.pos(u'이것도 되나욬ㅋㅋ', norm=True))\n",
    "print(okt.pos(u'이것도 되나욬ㅋㅋ', norm=True, stem=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
