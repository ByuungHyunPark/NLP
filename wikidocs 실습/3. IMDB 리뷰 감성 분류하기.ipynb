{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 링크 : https://wikidocs.net/24586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB 리뷰 감성 분류하기(IMDB Movie Review Sentiment Analysis)\n",
    "----\n",
    "IMDB 는 영화 사이트이며 , 감성 분류 연습을 위해 자주 사용되는 대표적인 데이터이다. 긍정인경우는 1, 부정인 경우는 0으로 표시한 레이블로 구성된 데이터이다.\n",
    "\n",
    "케라스에서는 해당 IMDB 영화 리뷰 데이터를 imdb.load_data() 함수를 통해 바로 다운로드 할 수 있도록 지원하고 있습니다. 케라스로부터 해당 데이터를 다운로드 받아 감성 분류를 수행하는 모델을 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X : text Data    // Y : Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = imdb.load_data()\n",
    "#(X_train, y_train) , (X_test, y_test) = imdb.load_data(num_words = 10000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 25000\n",
      "테스트용 리뷰 개수 : 25000\n",
      "카테고리 : 2\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 리뷰 개수 : {}'.format(len(X_train)))\n",
    "print('테스트용 리뷰 개수 : {}'.format(len(X_test)))\n",
    "num_classes = max(y_train) + 1\n",
    "print('카테고리 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# X train 구조 확인 => 모두 Emebedding 되어있음을 확인 할 수 있다.\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25,000 개의 훈련용 리뷰 데이터의 리뷰 길이 그래프로 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 2494\n",
      "리뷰의 평균 길이 : 238.71364\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcLUlEQVR4nO3df3BV5b3v8ffHCEFRMalBKeih7QSK0tYeMl7uyHQOx6vSnvHo+aNT4txKNdMcHcvUQR0i+aM9dyYWrcczyr2YokFxLg3DnLYjo2JLuel0YDzaoB4VUoTWFqkMUNSRi1ck5Hv/2E9wk4T8gCR7Z6/Pa2bNWvu71tp51mTz5cmznx+KCMzMLBvOKnQBzMxs9Djpm5lliJO+mVmGOOmbmWWIk76ZWYacXegCDOSiiy6K6dOnF7oYVqK2bdv214ioGu2f68+1jaT+PtdFn/SnT59Oe3t7oYthJUrSnwvxc/25tpHU3+fazTtmZhnipG9mliFO+mZmGeKkb2aWIU76ZmYZMmDSl3SppDZJHZK2S/p+iv9Q0l8kvZa2b+Tdc5+k3ZJ2Sro+Lz5H0hvp3KOSNDKPlT2tra3Mnj2bsrIyZs+eTWtra6GLZGZFaDBdNjuBuyPiFUnnA9skbUrn/i0iHsq/WNLlwELgCuCzwK8lzYiI48BjQD3wH8DzwAJg4/A8Sna1trbS2NhIS0sL8+bNY8uWLdTV1QFQW1tb4NKZWTEZsKYfEfsi4pV0fBjoAKb2c8uNwLqIOBoRbwO7gaskTQEuiIgXIzef89PATWf6AAZNTU20tLQwf/58xo0bx/z582lpaaGpqanQRTOzIjOkNn1J04GvAi+l0PckvS5ptaSKFJsKvJN3294Um5qOe8b7+jn1ktoltR88eHAoRcykjo4O5s2bd1Js3rx5dHR0FKhEY8POnTsBLs9rovxQ0l2SKiVtkrQr7bs/2266tDFv0Elf0nnAz4C7IuJDck01XwCuBPYB/9p9aR+3Rz/x3sGIVRFRExE1VVWjPkJ+zJk1axZbtmw5KbZlyxZmzZpVoBKNDTNnzgTYERFXAnOAj4BfAA3A5oioBjan1z2bLhcAKyWVpbfrbrqsTtuC4S7v9IbnTmxmp2tQSV/SOHIJf21E/BwgIvZHxPGI6AIeB65Kl+8FLs27fRrwbopP6yNuZ6ixsZG6ujra2to4duwYbW1t1NXV0djYWOiijSXXAH+IiD+Ta6Jck+Jr+LQZ0k2XNuYN+EVu+jO1BeiIiIfz4lMiYl96+U/Am+l4A/BTSQ+T+yK3Gng5Io5LOixpLrnmoVuAFcP3KNnV/WXt4sWL6ejoYNasWTQ1NflL3KFZCHR3ebq4+7MdEfskTU7xqeQ6IXTrbqI8xiCaLiXVk/trgMsuu2xYC282WIPpvXM18G3gDUmvpdgyoFbSleSaaP4E/DNARGyXtB7YQa7nz52p5w7AHcBTwDnkeu24584wqa2tdZI/TZLGA/8I3DfQpX3EBt10GRGrgFUANTU1XpzaCmLApB8RW+j7Q/18P/c0Ab26jkREOzB7KAU0GwVfB16JiP3p9f7uv2RT082BFHfTpY15HpFrBrV82rQDuSbKRel4EfBMXnyhpHJJn+PTpst9wGFJc1Nz6C1595gVlaKfT99shJ0FXEtqnkyWA+sl1QF7gG+Cmy6tNDjpW9Z1RcRn8gMRcYhcb55e3HRpY52bd8zMMsRJ38wsQ5z0zcwyxEnfzCxDnPTNzDLESd/MLEOc9M3MMsRJ38wsQ5z0zcwyxEnfzCxDnPTNzDLESd/MLEOc9M3MMsRJ38wsQ5z0zcwyxEnfzCxDnPTNzDLESd/MLEOc9M3MMsRJ38wsQ5z0LevKJP27pN9L6pD0XyVVStokaVfaV3RfLOk+Sbsl7ZR0fV58jqQ30rlHJakwj2PWPyd9y7pLgRci4ovAV4AOoAHYHBHVwOb0GkmXAwuBK4AFwEpJZel9HgPqgeq0LRjNhzAbLCd9y6wPP/wQ4HygBSAiPomID4AbgTXpsjXATen4RmBdRByNiLeB3cBVkqYAF0TEixERwNN595gVFSd9y6w//vGPAJ3Ak5JelfSEpInAxRGxDyDtJ6dbpgLv5L3F3hSbmo57xk8iqV5Su6T2gwcPDvvzmA2Gk75lVmdnJ8C5wGMR8VXgCKkp5xT6aqePfuInByJWRURNRNRUVVWdRonNzpyTvmXWtGnTAD6JiJdS6N+BvwX2pyYb0v5AOr+X3HcAJ94CeDfFp/URNys6TvqWWZdccgnAJ5JmptA1wA5gA7AoxRYBz6TjDcBCSeWSPkfuC9uXUxPQYUlzU6+dW/LuMSsqAyZ9SZdKakvd2bZL+n6Ku1ublYI9wFpJrwNXAvcDy4FrJe0Crk2viYjtwHpy/zG8ANwZEcfT+9wBPEHuy90/ABtH8RnMBu3sQVzTCdwdEa9IOh/YJmkT8B1y3dqWS2og1xa6tEe3ts8Cv5Y0I/3j6O7W9h/A8+S6tfkfhxXS/4uImj7i1/R1cUQ0AU19xNuB2cNcNrNhN2BNPyL2RcQr6fgwuX7MU3G3NjOzMWdIbfqSpgNfBV5ihLq1mZnZyBl00pd0HvAz4K6I+LC/S/uIDbpbW/pZ7s9sZjYCBpX0JY0jl/DXRsTPU3jEurW5P7OZ2cgYTO8dkRum3hERD+edcrc2M7MxZjC9d64Gvg28Iem1FFtGrhvbekl15Lq9fRNy3dokdXdr66R3t7angHPI9dpxzx0zs1E0YNKPiC303R4P7tZmZjameESumVmGOOmbmWWIk76ZWYY46ZeIxYsXM2HCBCQxYcIEFi9eXOgimVkRctIvAYsXL6a5uZn777+fI0eOcP/999Pc3OzEb2a9OOmXgMcff5wHHniAJUuWcO6557JkyRIeeOABHn/88UIXzcyKjJN+CTh69Ci33377SbHbb7+do0ePFqhEZlasnPRLQHl5Oc3NzSfFmpubKS8vL1CJzKxYDWZErhW57373uyxduhTI1fCbm5tZunRpr9q/mZmTfglYsWIFAMuWLePuu++mvLyc22+//UTczKybk36JWLFihZO8mQ3IbfpmZhnipG9mliFO+iWitbWV2bNnU1ZWxuzZs2ltbS10kcaKL0l6Q9JrktoBJFVK2iRpV9pXdF8s6T5JuyXtlHR9XnxOep/dkh5Na0aYFR0n/RLQ2tpKY2MjK1as4OOPP2bFihU0NjY68Q/e/Ii4MiJq0usGYHNEVAOb02skXQ4sBK4AFgArJZWlex4D6sktGlSdzpsVHSf9EtDU1ERLSwvz589n3LhxzJ8/n5aWFpqaei1pYINzI7AmHa8BbsqLr4uIoxHxNrAbuCotF3pBRLwYEQE8nXePWVFx0i8BHR0dzJs376TYvHnz6OjoKFCJxpxfSdomqT69vjgt70naT07xqcA7efftTbGp6bhn3KzoOOmXgFmzZrFly5aTYlu2bGHWrFkFKtGY8vuI+Fvg68Cdkr7Wz7V9tdNHP/GTb5bqJbVLaj948ODpldbsDDnpl4DGxkbq6upoa2vj2LFjtLW1UVdXR2NjY6GLNhYcA4iIA8AvgKuA/anJhrQ/kK7dC1yad+804N0Un9ZH/CQRsSoiaiKipqqqarifw2xQPDirBNTW1gK5KZY7OjqYNWsWTU1NJ+LWtyNHjkCq+EiaCFwH/A9gA7AIWJ72z6RbNgA/lfQw8FlyX9i+HBHHJR2WNBd4CbgF8Eg5K0pO+iWitrbWSX6I9u/fD/BFSf9J7t/CTyPiBUm/A9ZLqgP2AN8EiIjtktYDO4BO4M6IOJ7e7g7gKeAcYGPazIqOm3dKhPvpD93nP/95gB0R8ZWIuCIimgAi4lBEXBMR1Wn/Xvc9EdEUEV+IiJkRsTEv3h4Rs9O576VePGZFxzX9EtDdT7+lpYV58+axZcsW6urqAFz7N7OTuKZfAtxP38wGy0m/BLifvpkNlpN+CXA/fTMbLLfpl4DGxka+9a1vMXHiRPbs2cNll13GkSNHeOSRRwpdNDMrMq7plxh3GjGz/jjpl4Cmpibq6+uZOHEikpg4cSL19fX+ItfMenHzTgnYsWMH+/fv57zzzgNyI01/8pOfcOjQoQKXzMyKjWv6JaCsrIyuri5Wr17Nxx9/zOrVq+nq6qKsrGzgm80sUwZM+pJWSzog6c282A8l/SWtNvSapG/knfPKQqOss7OT8ePHnxQbP348nZ2dBSqRmRWrwdT0n6LvVYD+La02dGVEPA9eWaiQbr31VhYvXsyECRNYvHgxt956a6GLZGZFaMCkHxG/Bd4b6LrEKwsVwLRp03jyySdPWi7xySefZNq0aQPfbGaZciZt+t+T9Hpq/uleOHpYVhbyYhND8+CDD3L8+HFuu+02ysvLue222zh+/DgPPvhgoYtmZkXmdJP+Y8AXgCuBfcC/pvgZrSx04oQXmxiS2tpaHnnkkZO6bD7yyCOebK2ETW94jukNzxW6GDYGnVaXzYjY330s6XHg2fTyjFYWstPn+fTNbDBOq6bfvZRc8k9Ad8+eDcBCSeWSPsenKwvtAw5Lmpt67dzCp6sRmZnZKBmwpi+pFfg74CJJe4EfAH8n6UpyTTR/Av4ZvLKQmVmxG0zvndqImBIR4yJiWkS0RMS3I+JLEfHliPjHVJPvvt4rCxVAd3dNSSe6bZqZ9eQRuSVg8eLFrFy5kgsvvBCACy+8kJUrVzrxm1kvTvoloLm5mUmTJtHa2sonn3xCa2srkyZNorm5udBFM7Mi46RfAjo7O1m7du1JyyWuXbvW0zCYWS9O+iXizTff7Pe1nZqkVyU9m44rJW2StCvtK/Ku87xSNuY56ZeAyspKGhoauOSSS5DEJZdcQkNDA5WVlYUu2lhwMZC/mHADsDkiqoHN6bXnlbKS4aRfAm6++WYi4sT8+YcOHSIiuPnmmwtcsuK2d+9egEnAE3nhG4E16XgNn84R5XmlrCQ46ZeAtrY2li1bxsyZMznrrLOYOXMmy5Yto62trdBFK2p33XUX5EaLd+WFL+7ugpz2k1P8jOeV8pxSVgyc9EtAR0cH7733Hrt376arq4vdu3fz3nvv0dHRMfDNGfXss88yefJkgI8GecsZzyvlOaWsGDjpl4ALL7yQ5uZmKioqOOuss6ioqKC5uflEv33rbevWrWzYsAHgS8A64O8l/W9gf/c0I2l/IN3ieaWsJDjpl4APPvgASdx7770cPnyYe++9F0l88MEHhS5a0frRj37U3ab/BrkvaP9PRPx3cvNHLUqXLeLTOaI8r5SVBCf9EtDV1cU999zD6tWrOf/881m9ejX33HMPXV1dA99sPS0HrpW0C7g2vSYitgPd80q9QO95pZ4g9+XuH/C8UlbETmtqZSs+F1100Ul983/84x8XsDRjS0T8BvhNOj4EXHOK65qApj7i7cDskSuh2fBxTb8EVFZWsnTpUqZMmUJZWRlTpkxh6dKl7qdvZr046ZeA7v74Bw8epKuri+7ugO6nb2Y9OemXgLa2NubMmXOiDb+rq4s5c+a4n76Z9eKkXwJ27NjBq6++ykMPPcSRI0d46KGHePXVV9mxY0ehi2ZmRcZJv0TU19ezZMkSzj33XJYsWUJ9fX2hi2RmRchJvwREBBs3bqStrY1jx47R1tbGxo0b8eJkZtaTu2yWgPLycsaPH88111xDRCCJ6upqysvLC100MysyrumXgBkzZvDWW29xww03cPDgQW644QbeeustZsyYUeiimVmRcU2/BLz11ltcffXV/PKXv6Sqqory8nKuvvpq2tvbC100MysyTvol4OjRo/zqV7/i3HPPPRH76KOPmDhxYgFLZWbFyM07JaC8vJzrrruOCRMmIIkJEyZw3XXXuU3fzHpx0i8BM2bMYOvWrYwfP56zzjqL8ePHs3XrVrfpm1kvbt4pAR0dHUji8OHDABw+fBhJXkTFzHpxTb8EdHZ2EhFUVFQgiYqKCiKCzs7OQhfNzIqMk36JKCsrY9KkSUhi0qRJlJWVFbpIZlaE3LxTIo4fP86ePXvo6uo6sTcz68k1/RKSP8ummVlfnPTNzDLESd/MLEMGTPqSVks6IOnNvFilpE2SdqV9Rd65+yTtlrRT0vV58TmS3kjnHpWk4X8cMzPrz2Bq+k8BC3rEGoDNEVENbE6vkXQ5sBC4It2zUlJ3N5LHgHqgOm0939NsVH388ccAsyT9p6Ttkv4FXKmx0jZg0o+I3wLv9QjfCKxJx2uAm/Li6yLiaES8DewGrpI0BbggIl6M3CTvT+fdY1YQaZqKnRHxFeBKYIGkubhSYyXsdNv0L46IfQBpPznFpwLv5F23N8WmpuOe8T5JqpfULqm9e5Fvs+GWKuPdXZ3GpS1wpcZK2HB/kdvXn7TRT7xPEbEqImoioqaqqmrYCmfWF0mvAQeATRHxEiNUqXFlxorB6Sb9/al2Q9ofSPG9wKV5100D3k3xaX3EzQouIq4k95m8StLsfi49o0qNKzNWDE436W8AFqXjRcAzefGFksolfY5c2+bLqbZ0WNLc9AXXLXn3mBVcRHwA/IZcW7wrNVayBtNlsxV4EZgpaa+kOmA5cK2kXcC16TURsR1YD+wAXgDujIjj6a3uAJ4g1w76B2DjMD+L2ZCkJpYyAEnnAP8N+D2u1FgJG3DunYioPcWpa05xfRPQ1Ee8HejvT2ezUbVv3z7IVWZeJ1cBWh8Rz0p6EVifKjh7gG9CrlIjqbtS00nvSs1TwDnkKjSu1FhR8oRrlllf/vKXAXZERE1+PCIO4UqNlShPw2BmliFO+mZmGeKkb2aWIU76ZmYZ4i9yzcaw6Q3PnTj+0/J/KGBJbKxwTd/MLEOc9M3MMsRJ38wsQ5z0zcwyxF/kmhWx/C9qzYaDa/pmZhnipG9mliFO+mZmGeKkb2aWIU76ZmYZ4qRvZpYhTvpmZhnipG9mliFO+mZmGeKkb2aWIU76llnvvPMOwAxJHZK2S/o+gKRKSZsk7Ur7iu57JN0nabeknZKuz4vPkfRGOveoJI3+E5kNzEnfMuvss88G2BsRs4C5wJ2SLgcagM0RUQ1sTq9J5xYCVwALgJWSytLbPQbUA9VpWzCKj2I2aE76lllTpkwB+AggIg4DHcBU4EZgTbpsDXBTOr4RWBcRRyPibWA3cJWkKcAFEfFiRATwdN49ZkXFSd8MkDQd+CrwEnBxROwDSPvJ6bKpwDt5t+1NsanpuGe858+ol9Quqf3gwYPD/gxmg+Gkb5kn6TzgZ8BdEfFhf5f2EYt+4icHIlZFRE1E1FRVVZ1eYc3OkJO+ZZ3IJfy1EfHzFNufmmxI+wMpvhe4NO/eacC7KT6tj7hZ0XHSt8zKNb/zN0BHRDycd2oDsCgdLwKeyYsvlFQu6XPkvrB9OTUBHZY0N/XauSXvHrOi4pWzLLO2bt0K8Bng7yW9lsLLgOXAekl1wB7gmwARsV3SemAH0AncGRHH0313AE8B5wAb02ZWdJz0LbPmzZsHsC0iavo4fU1f90REE9DUR7wdmD2sBTQbAW7eMTPLkDNK+pL+lEYhviapPcWGPJrRhk7SiW0w15mZwfA078yPiL/mve4ezbhcUkN6vbTHaMbPAr+WNCOvTdSGIH0JCdBvUs+/zkrb9IbnThz/afk/FLAkVsxGonlnSKMZR+Dnm5nZKZxp0g/gV5K2SapPsaGOZuzFIxeH5lS1edfyzaynM23euToi3pU0Gdgk6ff9XDuoUYuQG7kIrAKoqalx5hqE7gQvycnezE7pjGr6EfFu2h8AfkGuuWaooxnNzGyUnHbSlzRR0vndx8B1wJsMcTTj6f58MzMbujNp3rkY+EXqOXI28NOIeEHS7xj6aEYzMxsFp530I+KPwFf6iB9iiKMZzcxsdHhErplZhjjpm5lliJO+mVmGOOmbmWWIp1Y2K0Geh8dOxTV9M7MMcdI3M8sQJ30zswxx0jczyxAnfTOzDHHSt8y67bbbAL4i6c3u2Oks9ylpTlo2dLekR+X1Ka2IOekXucrKypPWwx1oAwZ9bWVlZYGfrrC+853vAOzqEe5e7rMa2Jxe02O5zwXASkll6Z7HgHpyM8dWp/NmRclJv8i9//77RMSIbO+//36hH6+gvva1r0Fuxtd8Q1ruM60ZcUFEvBi51WuezrvHrOg46ZudbKjLfU5Nxz3jZkXJI3LNBudUy30OehnQtI50PcBll112yh+UP5p2OHS/n0fmGrimb9bTUJf73JuOe8Z7iYhVEVETETVVVVXDXnCzwXDSNzvZkJb7TE1AhyXNTb12bsm7x6zouHnHMqu2thbgi4Ak7QV+ACxn6Mt93gE8BZwDbEybWVFy0rfMam1tZd26da9HRE2PU0Na7jMi2oHZI1BEs2Hn5h0zswxxTb/IxQ8ugB9OGrn3NrNMcdIvcvqXD8mN+RmB95aIH47IW5tZkXLSN8sIr6Zl4KQ/JozU/F0VFRUDX2RmJcVJv8gNtWlH0og1B5nZ2OfeO2ZmGeKavlkGuX0/u1zTNzPLECd9M7MMcdI3M8sQt+mbZZzb97Nl1Gv6khakhaV3S2oY7Z9vZpZlo5r000LS/wv4OnA5UJsWnDYzs1Ew2jX9q4DdEfHHiPgEWEduwWkbIkl9bqc6ZzYY0xueG/blGq24jHbSP9Xi0ieRVC+pXVL7wYMHR61wY0lEDGkzM4PR/yJ3UItIR8QqYBVATU2NM5bZKPOXu6VrtGv6p1pc2szMRsFo1/R/B1SnhaX/AiwEbh7lMpjZELjWX1pGNelHRKek7wG/BMqA1RGxfTTLYGanz/8BjH2jPjgrIp4Hnh/tn2tmw6uvXj7+j6D4eUSu2TCRtAB4hNxfsU9ExPICF2nUneovAf8HUTyc9M2GQd7Aw2vJdVj4naQNEbGjsCUrHPf3L06ecM1seHjgoY0JRV/T37Zt218l/bnQ5RhDLgL+WuhCjCF/M0zv09fAw/+Sf4GkeqA+vfy/knae4r1K+Xd44tn0QIFLMjKK5Xd3ys910Sf9iKgqdBnGEkntEVFT6HJk0IADD/MHHfb7RiX8OyzlZ4Ox8Xxu3jEbHh54aGOCk77Z8Dgx8FDSeHIDDzcUuExmvRR9844N2YDNBzb8hnngYSn/Dkv52WAMPJ88A6OZWXa4ecfMLEOc9M3MMsRJv0RIWi3pgKQ3C10WOz1jdf3ovj57kiolbZK0K+0r8s7dl55xp6Tr8+JzJL2Rzj2qIljyTdKlktokdUjaLun7KT5mn89Jv3Q8BSwodCHs9Izx9aOfovdnrwHYHBHVwOb0mvRMC4Er0j0r07MDPEZu8Fp12orh89wJ3B0Rs4C5wJ3pGcbs8znpl4iI+C3wXqHLYadtzE7jcIrP3o3AmnS8BrgpL74uIo5GxNvAbuAqSVOACyLixcj1Lnk6756CiYh9EfFKOj4MdJAbfT1mn89J36w4DGr96DHk4ojYB7nECUxO8VM959R03DNeNCRNB74KvMQYfj4nfbPiMKj1o0vAqZ6zqJ9f0nnAz4C7IuLD/i7tI1ZUz+ekb1YcSm0ah/2pSYO0P5Dip3rOvem4Z7zgJI0jl/DXRsTPU3jMPp+TvllxKLVpHDYAi9LxIuCZvPhCSeVprexq4OXURHJY0tzUq+WWvHsKJpWlBeiIiIfzTo3d54sIbyWwAa3APuAYuVpFXaHL5G3Iv8NvAG8BfwAaC12eIZS712cP+Ay5Xi270r4y7/rG9Iw7ga/nxWuAN9O5/0maMaDAzzaPXDPM68BrafvGWH4+T8NgZpYhbt4xM8sQJ30zswxx0jczyxAnfTOzDHHSNzPLECd9M7MMcdI3M8uQ/w9VVVxGp1JXAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_result = [len(s) for s in X_train]\n",
    "\n",
    "print('리뷰의 최대 길이 : {}'.format(np.max(len_result)))\n",
    "print('리뷰의 평균 길이 : {}'.format(np.mean(len_result)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(len_result)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(len_result, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 레이블에 대한 빈도수:\n",
      "[[    0     1]\n",
      " [12500 12500]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 레이블에 대한 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMDB 리뷰 데이터는 0,1,2,3 인덱스를 중요시 여긴다고 함 // 데이터셋의 특징이므로 , 큰 신경 안써도 될듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word={}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value+3] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 1등 단어 : the\n"
     ]
    }
   ],
   "source": [
    "print('빈도수 상위 1등 단어 : {}'.format(index_to_word[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 3938등 단어 : suited\n"
     ]
    }
   ],
   "source": [
    "print('빈도수 상위 3938등 단어 : {}'.format(index_to_word[3941]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X_train[0] 의 데이터는 아래와 같음을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in X_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSTM으로 IMDB 리뷰 감성 분류하기\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 단어 집합의 크기를 10,000 으로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pad_sequences() : 훈련 데이터가 정한 길이를 초과하면 초과분을 삭제하고, 부족하면 0으로 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Embedding() \n",
    "- 첫번째 인자 : 단어 집합의 크기\n",
    "- 두번째 인자 : 임베딩 후의 벡터 크기<br>\n",
    "##### 즉 , 아래에서는 모든 입력데이터에서 모든 단어는 100차원의 임베딩 벡터로 표현됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__검증 데이터 손실이 4회 증가하면 학습을 중단하는 조기 종료(EarlyStopping)를 사용합니다. <br>\n",
    "또한, ModelCheckpoint를 사용하여 검증 데이터의 정확도가 이전보다 좋아질 경우에만 모델을 저장하도록 합니다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1 , patience = 4)\n",
    "mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode = 'max', verbose = 1 , save_best_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이진 분류 이므로 , 출령층을 뉴런 하나와 , 활성화 함수로 시그모이드 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/15\n",
      "19980/20000 [============================>.] - ETA: 0s - loss: 0.5080 - acc: 0.7532\n",
      "Epoch 00001: val_acc improved from -inf to 0.84500, saving model to GRU_model.h5\n",
      "20000/20000 [==============================] - 27s 1ms/sample - loss: 0.5084 - acc: 0.7531 - val_loss: 0.3612 - val_acc: 0.8450\n",
      "Epoch 2/15\n",
      "19980/20000 [============================>.] - ETA: 0s - loss: 0.3140 - acc: 0.8770\n",
      "Epoch 00002: val_acc improved from 0.84500 to 0.86980, saving model to GRU_model.h5\n",
      "20000/20000 [==============================] - 24s 1ms/sample - loss: 0.3139 - acc: 0.8770 - val_loss: 0.3121 - val_acc: 0.8698\n",
      "Epoch 3/15\n",
      "19980/20000 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.9089\n",
      "Epoch 00003: val_acc did not improve from 0.86980\n",
      "20000/20000 [==============================] - 23s 1ms/sample - loss: 0.2362 - acc: 0.9087 - val_loss: 0.3704 - val_acc: 0.8382\n",
      "Epoch 4/15\n",
      "19980/20000 [============================>.] - ETA: 0s - loss: 0.1799 - acc: 0.9349\n",
      "Epoch 00004: val_acc improved from 0.86980 to 0.89380, saving model to GRU_model.h5\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.1800 - acc: 0.9348 - val_loss: 0.2570 - val_acc: 0.8938\n",
      "Epoch 5/15\n",
      "19980/20000 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9506\n",
      "Epoch 00005: val_acc improved from 0.89380 to 0.90180, saving model to GRU_model.h5\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.1403 - acc: 0.9506 - val_loss: 0.2563 - val_acc: 0.9018\n",
      "Epoch 6/15\n",
      "19980/20000 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9598\n",
      "Epoch 00006: val_acc did not improve from 0.90180\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.1112 - acc: 0.9597 - val_loss: 0.3153 - val_acc: 0.8916\n",
      "Epoch 7/15\n",
      "19980/20000 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9719\n",
      "Epoch 00007: val_acc did not improve from 0.90180\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.0856 - acc: 0.9719 - val_loss: 0.3014 - val_acc: 0.8880\n",
      "Epoch 8/15\n",
      "19980/20000 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9783\n",
      "Epoch 00008: val_acc did not improve from 0.90180\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.0649 - acc: 0.9783 - val_loss: 0.3713 - val_acc: 0.8912\n",
      "Epoch 9/15\n",
      "19980/20000 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9844\n",
      "Epoch 00009: val_acc did not improve from 0.90180\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 0.0494 - acc: 0.9844 - val_loss: 0.4662 - val_acc: 0.8806\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs = 15, callbacks = [es, mc], batch_size = 54, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load model에서 OS Error 뜨는데 , 오류에 대한 설명도 없고 ,, 구글링 아무리해도 해결못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d9b5bb19b28c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n 테스트 정확도: %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    143\u001b[0m   \"\"\"\n\u001b[0;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[1;32m--> 145\u001b[1;33m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\base.py\u001b[0m in \u001b[0;36mis_hdf5\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.is_hdf5\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 훈련과정중 가장 정확도 높앗을 때 저장된 모델이 아닌 , 마지막 시점의 모델을 사용한것이라 , 정확도는 좀 더 낮을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 검증\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    # 알파벳과 숫자를 제외하고 모두 제거 및 알파벳 소문자화\n",
    "    new_sentence = re.sub('[^0-9a-zA-Z ]', '' , new_sentence).lower()\n",
    "    \n",
    "    # 정수 인코딩\n",
    "    encoded = []\n",
    "    for word in new_sentence.split():\n",
    "        # 단어 집합의 크기를 10,000으로 제한\n",
    "        try:\n",
    "            if word_to_index[word] <= 10000:\n",
    "                encoded.append(word_to_index[word] + 3)\n",
    "            else:\n",
    "            # 10,000 이상의 숫자는 <unk> 토큰으로 취급\n",
    "                encoded.append(2)\n",
    "        \n",
    "        \n",
    "        # 단어 집합에 없는 단어는 <unk> 토큰으로 취급.\n",
    "        except KeyError:\n",
    "            encoded.append(2)\n",
    "            \n",
    "    pad_new = pad_sequences([encoded], maxlen = max_len) # 패딩\n",
    "    score = float(model.predict(pad_new)) # 예측\n",
    "    \n",
    "    if(score > 0.5):\n",
    "        print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
    "    else:\n",
    "        print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format(( 1 - score) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMDB 사이트에서 영화 블랙팬서의 1점 리뷰를 활용하여 , 부정으로 제대로 예측하는지 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_str = \"This movie was just way too overrated. The fighting was not professional and in slow motion. I was expecting more from a 200 million budget movie. The little sister of T.Challa was just trying too hard to be funny. The story was really dumb as well. Don't watch this movie if you are going because others say its great unless you are a Black Panther fan or Marvels fan.\"\n",
    "\n",
    "sentiment_predict(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_str = \" I was lucky enough to be included in the group to see the advanced screening in Melbourne on the 15th of April, 2012. And, firstly, I need to say a big thank-you to Disney and Marvel Studios. \\\n",
    "Now, the film... how can I even begin to explain how I feel about this film? It is, as the title of this review says a 'comic book triumph'. I went into the film with very, very high expectations and I was not disappointed. \\\n",
    "Seeing Joss Whedon's direction and envisioning of the film come to life on the big screen is perfect. The script is amazingly detailed and laced with sharp wit a humor. The special effects are literally mind-blowing and the action scenes are both hard-hitting and beautifully choreographed.\"\n",
    "\n",
    "sentiment_predict(temp_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- 긍정과 부정에 대한 정확도가 상당히 높음을 볼 수 있었습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
